{"cells":[{"metadata":{},"cell_type":"markdown","source":"# General Notes\nBy Ryan Cox\n\nI find version control useful for me so I'm keeping my work in a git repo. You can find it here: https://github.com/Infinite-Improbability/math322-inverse-theory\n\nMy experience, as discussed, is in Python. However, I decided that if I'm going to be doing a lot of matrix work I'd use something with native support and better performance. MatLab is, of course, great with matrices but I prefer something a bit more open. Enter Julia, which is both fast and designed with linear algebra and scientific computing in mind. I've been interested in learning it, so here we go."},{"metadata":{},"cell_type":"markdown","source":"# Q1 | Problem 1.1\n\nWe are measuring subsets of objects. The data is the measured masses of the subsets (mostly triplets of objects). The parameters are the masses of the individual objects. There are 100 data values and 100 parameters."},{"metadata":{"trusted":false},"cell_type":"code","source":"# Lets find the matrix G such that d=Gm\n#= NB: Julia's compiler apparently has better performance for functions than top level code\nWe don't need the performance gains here but I'll do it anyway to develop the habit.\nLikewise, we'll use a sparse array. It won't matter for the relatively small matrices we're working with here,\nbut it may help if the function is used for something large.\n\nUsing a dense matrix causes an out of memory error with a large matrix (N=100000).\nAn alternate version of the below code involved insertions into a sparse matrix. That takes ~5.7s with N=100000. It can be viewed on commit 4c7e7ae\nThe following version is harder to read but handles N=100000 in ~0.0088s.\n\nYes, I know all this optimisation wasn't necessary. But it was fun!\n=#\n\nusing SparseArrays\n\n\"\"\"Make NxN square matrix and fill it with triplets of a coefficent a.\nIn a row with index r, the cells [r, r], [r, r-1], [r, r-2] are filled.\nArgument a multipes the entire matrix by scalar a.\nFor example TripletsMatrix(5, 1) produces the sparse matrix\n   [1 0 0 0 0;\n    1 1 0 0 0;\n    1 1 1 0 0;\n    0 1 1 1 0;\n    0 0 1 1 1]\"\"\"\nfunction TripletsMatrix(N::Int, a=1::Number)::SparseMatrixCSC  # a is probably unneccessary (vs hardcoding a=1) except in some odd cases, but including it is trivial.\n    #= We are creating a matrix with COO, a coordinate list.\n    For some k, row[k] gives row index, col[k] gives col index and val[k] gives the value for that coordinate pair.\n    We create the matrices in advance then increment over vector coordiantes with k because it is reportedly faster than appending to matrices. =#\n    \n    if N < 2 error(\"N should be at least 2.\") end\n    \n    col = Vector{Int64}(undef, 3*(N-1)) # 3*(N-1) should be the amount of nonzero values <- 3 from the first two rows and 3*(N-2) from the rest.\n    row = Vector{Int64}(undef, 3*(N-1))\n    val = Vector{Float64}(undef, 3*(N-1))\n    k = 1 # This tracks our location in the COO vectors\n    for i = 1:N # Row index.\n        for j in i-2:i # Column index, for non-zero values. We don't write to any columns higher than i so this doesn't do anything weird in the last row.\n            if j > 0 # To handle first two rows.\n                col[k] = j\n                row[k] = i\n                val[k] = a\n                k += 1\n            end\n        end\n    end\n    sparse(row, col, val) # Takes our vectors and turns them into a sparse matrix\nend;","execution_count":48,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"N = 100 # Number of objects\nG = TripletsMatrix(N)\n\ndisplay(G) # Julia prints larges sparse matrices in this dot format that merely highlights non-zero values. This is much more compact than the full matrix.\nprintln()\nprintln(\"\"\"While this appears to show only two values in some places inspection of those rows, as below, shows this is not the case.\n    I was confused as to why, until a friend realised it uses Braille characters to represent the structure, so it isn't a perfect representation.\"\"\")\nprintln(\"Row 4, non-zero values:\")\nprintln(G[4,:])\nprintln()\n\n# What % of G is 0?\n# nnz returns number of stored values. This can include zero if you have told it to store 0 somewhere! dropzeros can be handy to remove nonstructual zeros.\npercent = (1 - nnz(G) / N^2) * 100\nprintln(string(percent) * \"% of G is zero\")","execution_count":40,"outputs":[{"data":{"text/plain":"100×100 SparseMatrixCSC{Float64, Int64} with 297 stored entries:\n⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⠷⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄⠀⠀\n⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠙⢳⣄"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"\nWhile this appears to show only two values in some places inspection of those rows, as below, shows this is not the case.\nI was confused as to why, until a friend realised it uses Braille characters to represent the structure, so it isn't a perfect representation.\nRow 4, non-zero values:\n  [2  ]  =  1.0\n  [3  ]  =  1.0\n  [4  ]  =  1.0\n\n97.03% of G is zero\n"}]},{"metadata":{},"cell_type":"markdown","source":"# Q2 | Problem 1.2\nWe are again measuring subsets of objects. The data is the height measurements of the subsets (stacks of objects). The parameters are the heights of the individual objects. This gives us 50 measurements and 50 parameters."},{"metadata":{"trusted":false},"cell_type":"code","source":"#= We'll just create NxN matrix filled with our coefficent and make a lower triangular matrix from it\nI experimented with sparse matrices but they weren't a good fit here. You can only really start using them after LowerTriangular so it just hurts performance. =#\n\nusing LinearAlgebra\n\nN = 50\nG = LowerTriangular(fill(1, (N, N)))\ndisplay(G)\n\npercent = (1 - count(!iszero, G) / N ^ 2) * 100\nprintln(string(percent) * \"% of G is zero\")","execution_count":3,"outputs":[{"data":{"text/plain":"50×50 LowerTriangular{Int64, Matrix{Int64}}:\n 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  ⋅  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n ⋮              ⋮              ⋮        ⋱        ⋮              ⋮           \n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1  …  1  1  1  1  1  1  1  1  ⋅  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  ⋅  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  ⋅  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  ⋅\n 1  1  1  1  1  1  1  1  1  1  1  1  1     1  1  1  1  1  1  1  1  1  1  1  1"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"49.0% of G is zero\n"}]},{"metadata":{},"cell_type":"markdown","source":"# Q3 | Problem 1.3"},{"metadata":{"trusted":false},"cell_type":"code","source":"z = Vector(LinRange(0, 10, 11)) # linear spacing, start=0, stop=10, # of values=11\nG = [ones(11) z z.^2 z.^3]\ndisplay(G)","execution_count":4,"outputs":[{"data":{"text/plain":"11×4 Matrix{Float64}:\n 1.0   0.0    0.0     0.0\n 1.0   1.0    1.0     1.0\n 1.0   2.0    4.0     8.0\n 1.0   3.0    9.0    27.0\n 1.0   4.0   16.0    64.0\n 1.0   5.0   25.0   125.0\n 1.0   6.0   36.0   216.0\n 1.0   7.0   49.0   343.0\n 1.0   8.0   64.0   512.0\n 1.0   9.0   81.0   729.0\n 1.0  10.0  100.0  1000.0"},"metadata":{},"output_type":"display_data"}]},{"metadata":{},"cell_type":"markdown","source":"# Q4 | Problem 1.4"},{"metadata":{"trusted":false},"cell_type":"code","source":"#= Unfortunately we aren't so lucky as to be able to directly reuse TripletsMatrix. Or rather, we could, but the tweaking we'd have to do after would be suboptimal.\nThis particular solution handles the endpoints by only overaging two values.\n=#\n\n\n\"\"\"Make NxN square matrix and fill it with triplets of coefficents so as to average groups of three neighbouring points.\nIn non-boundary row with index r, the cells [r, r], [r, r-1], [r, r-2] are filled with 1/3.\nThe first (last) row has been instead given 1/2 in the first (last) two columns so as to average two parameters.\nArgument a multipes the entire matrix by scalar a.\nFor example RunningAverageMatrix(5) produces the sparse matrix\n   [0.5  0.5  0    0    0;\n    0.3  0.3  0.3  0    0;\n    1    0.3  0.3  0.3  0;\n    0    0    0.3  0.3  0.3;\n    0    0    0    0.5  0.5]\nwhere 1/3 has been truncated to 0.3 for readability.\n\"\"\"\nfunction RunningAverageMatrix(N::Int, a=1::Number)::SparseMatrixCSC\n    # Avoid a potential error\n    if N < 3\n        error(\"Arguement N should be at least two.\")\n    end\n    \n    # This is COO again\n    T = 3 * N - 2 # 3*(N-2)+4 = 3*N-2 nonzero values <- 2 and 2 from the inital and final rows and 3*(N-2) from the rest.\n    col = Vector{Int64}(undef, T) \n    row = Vector{Int64}(undef, T)\n    val = Vector{Float64}(undef, T)\n    k = 3 # This tracks our location in the COO vectors. We start at 3 because we're skipping the first two values for now.\n    for i = 2:(N-1) # Row index. We start with the second row\n        for j in i-1:(i+1) # Column index, for non-zero values.\n            col[k] = j\n            row[k] = i\n            val[k] = a\n            k += 1\n        end\n    end\n    \n    # Hardcoding is ugly but it works. I didn't need to keep the vector indices corresponding with the LTR order of elements in the matrix but I find it more clear.\n    col[1] = 1\n    row[1] = 1\n    val[1] = (3/2)*a\n    col[2] = 2\n    row[2] = 1\n    val[2] = (3/2)*a\n    col[T-1] = N-1\n    row[T-1] = N\n    val[T-1] = (3/2)*a\n    col[T] = N\n    row[T] = N\n    val[T] = (3/2)*a\n    \n    (1/3) * sparse(row, col, val) # Takes our vectors and turns them into a sparse matrix\nend;","execution_count":49,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"N = 7\nG = RunningAverageMatrix(N)\ndisplay(G)\n\npercent = (1 - nnz(G) / N^2) * 100\nprintln(string(percent) * \"% of G is zero. This percentage increases with the size of the matrix.\")","execution_count":50,"outputs":[{"data":{"text/plain":"7×7 SparseMatrixCSC{Float64, Int64} with 19 stored entries:\n 0.5       0.5        ⋅         ⋅         ⋅         ⋅         ⋅ \n 0.333333  0.333333  0.333333   ⋅         ⋅         ⋅         ⋅ \n  ⋅        0.333333  0.333333  0.333333   ⋅         ⋅         ⋅ \n  ⋅         ⋅        0.333333  0.333333  0.333333   ⋅         ⋅ \n  ⋅         ⋅         ⋅        0.333333  0.333333  0.333333   ⋅ \n  ⋅         ⋅         ⋅         ⋅        0.333333  0.333333  0.333333\n  ⋅         ⋅         ⋅         ⋅         ⋅        0.5       0.5"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"61.224489795918366% of G is zero. This percentage increases with the size of the matrix.\n"}]},{"metadata":{},"cell_type":"markdown","source":"# Q5 | Problem 1.5\n\nWe know that\n$$ \\mathbf{S} = \\mathbf{CF} $$\n\nTypically $\\mathbf{S}$ is $s \\times c$, $\\mathbf{C}$ is $s \\times p$ and $\\mathbf{F}$ is $p\\times c$  where $s$ is the number of samples, $c$ is the number of chemicals and $p$ is the number of end-member rocks.\n\nGiven the constraints in the problem $s=1$ so $\\textbf{S}$ and $\\textbf{C}$ are row vectors and $\\textbf{F}$ is some matrix. $\\textbf{S}$ is the data, $\\textbf{C}$ and $\\textbf{F}$ are typically parameters. However, we know the compositions of the $p$ factors is known we can remove them from the parameters and consider this information an auxilary variable. Then it becomes clear that by taking the transpose of the entire equation we get\n$$ \\textbf{S}^T = (\\textbf{CF})^T = \\textbf{F}^T \\textbf{C}^T$$\nWhere $\\textbf{S}^T = \\textbf{d}$, $\\textbf{F}^T = \\textbf{G}$ and $\\textbf{C}^T = \\textbf{m}$.\n\nThis assumes we know the composition of the end factors exactly."},{"metadata":{},"cell_type":"markdown","source":"# Q6 | Problem 2.1"},{"metadata":{"trusted":false},"cell_type":"code","source":"using Distributions\n\nu = Uniform()\nprintln(\"Mean: \" * string(mean(u)))\nprintln(\"Variance: \" * string(var(u)))","execution_count":7,"outputs":[{"name":"stdout","output_type":"stream","text":"Mean: 0.5\nVariance: 0.08333333333333333\n"}]},{"metadata":{},"cell_type":"markdown","source":"Or manually (note use of bar for expected value - it renders better)\n\n$$ \\bar{d} = \\int_{-\\infty}^{\\infty} d p(d) \\mathrm{d}d $$\n$$ = \\int_0^1 d \\mathrm{d}d $$\n$$ = \\left[ \\frac{d^2}{2} \\right]^1_0 $$\n$$ = \\frac{1^2}{2} - \\frac{0^2}{2} = \\frac{1}{2} $$\nand\n$$ \\sigma^2 = \\int_{-\\infty}^{\\infty} (d-\\bar{d})^2 p(d) \\mathrm{d}d $$\n$$ = \\int_0^1 (d-0.5)^2 \\mathrm{d}d $$\n$$ = \\left[ \\frac{1}{3}(d-0.5)^3 \\right]^1_0 $$\n$$ = \\frac{1}{3} \\left( (1-0.5)^3 - (0-0.5)^3 \\right) $$\n$$ = \\frac{1}{3} \\left( 0.5^3 - (-0.5)^3 \\right) $$\n$$ = \\frac{1}{12} \\approx 0.08333 $$"},{"metadata":{},"cell_type":"markdown","source":"# Q7 | Problem 2.2"},{"metadata":{},"cell_type":"markdown","source":"$$ E=d^2 $$\n$$ d=\\pm \\sqrt{E} $$\n$$ \\left|\\frac{\\mathrm{d}d}{\\mathrm{d}E}\\right| = \\frac{1}{2\\sqrt{E}} $$\nSo using\n$$ p(m) = p[d(m)] \\left|\\frac{\\mathrm{d}d}{\\mathrm{d}m}\\right| $$\nwe get\n$$ p(E) = \\frac{1}{2\\sqrt{2\\pi E}}\\exp\\left[ \\frac{(\\sqrt{E} - \\bar{d})^2}{2\\sigma^2} \\right] $$"},{"metadata":{},"cell_type":"markdown","source":"# Q8\n\nThrough looking at a very recent (2021) article and then going back to the sources, I came accross *Estimating stellar mean density through seismic inversions* by Reese, Marques, Goupil, Thompson, and Deheuvels (https://doi.org/10.1051/0004-6361/201118156). The paper proposes ways to determine stellar mean density from measurements of stellar pulsation frequencies. In particular, it provides a framework for designing kernal based linear inversions that yield this density. It also presents three inversion techniques for this task and applies them to various test cases.\n\nThe data is discrete stellar pulsation frequencies. These are themselves derived from missions like COROT, which monitors variation in the brightness of stars caused by pulsation. The measurement of brightness and the subsequent conversion to frequencies are the first sources of error. In particular, surface effects may cause unrelated brightness changes. As best I can tell, Fourier analysis is used to take the measured spectrum and derive the frequencies of modes.\n\nDimensional analysis suggests that these frequencies scale with $\\sqrt{GM/R^3}$ and $<\\Delta v> \\propto \\sqrt{\\rho}$ where $<\\Delta v>$ is the large frequency seperation.\n\nOne method discussed, SOLA, obtains relative mean density variation $\\delta \\bar{\\rho}/{\\bar{\\rho}}$ (a discrete parameter) by minimising a particular cost function (eq 16 of article). This serves to minimise the difference between an averaging kernal and a particular target function $T(x) = 4\\pi x \\frac{\\rho}{\\rho_R}$. This particular method avoids having to determine the entire density variation profile, a continous parameter. Note $\\rho_R$ is density from a reference model.\n\nThe authors did not appear to address questions of existence, uniqueness or instability. This may be because the SOLA method is well established and these questions have been addressed in prior works."},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"julia-1.6","display_name":"Julia 1.6.1","language":"julia"},"language_info":{"file_extension":".jl","name":"julia","mimetype":"application/julia","version":"1.6.1"}},"nbformat":4,"nbformat_minor":4}